# -*- coding: utf-8 -*-
"""Копия блокнота "Влад.ipynb"

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YyGdPD8F20h7cYE61N4YkbvBJ7GB7Kes
"""

import pandas as pd

# === 1. Загрузка и парсинг данных продаж ===
file_path = "/content/Продажи со складов 1623243760 100.csv"
with open(file_path, 'r', encoding='utf-8') as f:
    lines = f.readlines()

# Убираем BOM и парсим первую строку с датами в формате дд-мм
raw_dates = lines[0].replace('\ufeff', '').strip().split(';')
dates = [d for d in raw_dates if '-' in d]

# Автоматическое определение года
parsed_dates = []
current_year = 2024
last_month = 0

for d in dates:
    try:
        day, month = map(int, d.split('-'))
        if last_month == 12 and month == 1:
            current_year += 1
        dt = pd.to_datetime(f"{day:02d}-{month:02d}-{current_year}", format='%d-%m-%Y')
        parsed_dates.append(dt)
        last_month = month
    except:
        parsed_dates.append(None)

date_map = pd.Series(parsed_dates)

# Парсинг строк с данными
parsed_data = []
for line in lines[2:]:
    parts = line.strip().split(';')
    warehouse = parts[0]
    values = parts[1:]
    for i in range(0, len(values) - 1, 2):
        idx = i // 2
        if idx < len(date_map):
            sales = values[i]
            stock = values[i + 1]
            parsed_data.append((warehouse, date_map[idx], sales, stock))

# === 2. DataFrame по выбранным складам ===
df_wh = pd.DataFrame(parsed_data, columns=['Склад', 'Дата', 'Продажи', 'Остатки'])

# Список нужных складов
selected_wh = [
    'ХОРУГВИНО_РФЦ',
    'ГРИВНО_РФЦ',
    'СОФЬИНО_РФЦ',
    'ПУШКИНО_1_РФЦ',
    'ЖУКОВСКИЙ_РФЦ',
    'ПЕТРОВСКОЕ_РФЦ',
    'НОГИНСК_РФЦ',
    'ТВЕРЬ_РФЦ'

]

# Фильтрация по списку
df_wh = df_wh[df_wh['Склад'].isin(selected_wh)]

# Приведение типов
df_wh['Продажи'] = pd.to_numeric(df_wh['Продажи'], errors='coerce')
df_wh['Остатки'] = pd.to_numeric(df_wh['Остатки'], errors='coerce')
df_wh['Дата']    = pd.to_datetime(df_wh['Дата'])

# === 3. Загрузка Excel с доп. столбцами ===
xls = pd.read_excel("/content/OZON - 1623243760 - 100.xlsx")
xls['Дата'] = pd.to_datetime(xls['Дата'], errors='coerce')
xls = xls[['Дата', 'Цена с Ozon Картой', 'Выручка', 'Комментариев', 'Рейтинг']]

# === 4. Загрузка погодных данных ===
weather_df = pd.read_csv("/content/moscow.csv")
weather_df['Дата'] = pd.to_datetime(weather_df['date'], errors='coerce')
weather_df = weather_df[['Дата', 'tavg', 'prcp']]

# === 5. Объединение таблиц ===
df_merged     = df_wh.merge(xls, on='Дата', how='left')
df_final_all  = df_merged.merge(weather_df, on='Дата', how='left')

# === 6. Сохранение результата ===
df_final_all.to_csv("итоговый_датасет.csv", index=False, encoding='utf-8-sig')

# Просмотр первых 10 строк итогового датасета
print(df_final_all.head(100))

df_final_all.shape

import pandas as pd

# === 1. Загрузка и парсинг данных продаж ===
file_path2 = "/content/Продажи со складов 1625802748 - 1002.csv"
with open(file_path2, 'r', encoding='utf-8') as f2:
    lines2 = f2.readlines()

# Убираем BOM и парсим первую строку с датами в формате дд-мм
raw_dates2 = lines2[0].replace('\ufeff', '').strip().split(';')
dates2 = [d for d in raw_dates2 if '-' in d]

# Автоматическое определение года
parsed_dates2 = []
current_year2 = 2024
last_month2 = 0

for d2 in dates2:
    try:
        day2, month2 = map(int, d2.split('-'))
        if last_month2 == 12 and month2 == 1:
            current_year2 += 1
        dt2 = pd.to_datetime(f"{day2:02d}-{month2:02d}-{current_year2}", format='%d-%m-%Y')
        parsed_dates2.append(dt2)
        last_month2 = month2
    except:
        parsed_dates2.append(None)

date_map2 = pd.Series(parsed_dates2)

# Парсинг строк с данными
parsed_data2 = []
for line2 in lines2[2:]:
    parts2 = line2.strip().split(';')
    warehouse2 = parts2[0]
    values2 = parts2[1:]
    for i2 in range(0, len(values2) - 1, 2):
        idx2 = i2 // 2
        if idx2 < len(date_map2):
            sales2 = values2[i2]
            stock2 = values2[i2 + 1]
            parsed_data2.append((warehouse2, date_map2[idx2], sales2, stock2))

# === 2. DataFrame по выбранным складам ===
df_wh2 = pd.DataFrame(parsed_data2, columns=['Склад', 'Дата', 'Продажи', 'Остатки'])

# Список нужных складов
selected_wh2 = [
    'ХОРУГВИНО_РФЦ',
    'ГРИВНО_РФЦ',
    'СОФЬИНО_РФЦ',
    'ПУШКИНО_1_РФЦ',
    'ЖУКОВСКИЙ_РФЦ',
    'ПЕТРОВСКОЕ_РФЦ',
    'НОГИНСК_РФЦ',
    'ТВЕРЬ_РФЦ'
]

# Фильтрация по списку
df_wh2 = df_wh2[df_wh2['Склад'].isin(selected_wh2)]

# Приведение типов
df_wh2['Продажи'] = pd.to_numeric(df_wh2['Продажи'], errors='coerce')
df_wh2['Остатки'] = pd.to_numeric(df_wh2['Остатки'], errors='coerce')
df_wh2['Дата']    = pd.to_datetime(df_wh2['Дата'])

# === 3. Загрузка Excel с доп. столбцами ===
xls2 = pd.read_excel("/content/OZON - 1625802748 - Продажи и остатки - 07.08.2024-06.05.2025. (07.05.2025) - 1002.xlsx")
xls2['Дата'] = pd.to_datetime(xls2['Дата'], errors='coerce')
xls2 = xls2[['Дата', 'Цена с Ozon Картой', 'Выручка', 'Комментариев', 'Рейтинг']]

# === 4. Загрузка погодных данных ===
weather_df2 = pd.read_csv("/content/moscow.csv")
weather_df2['Дата'] = pd.to_datetime(weather_df2['date'], errors='coerce')
weather_df2 = weather_df2[['Дата', 'tavg', 'prcp']]

# === 5. Объединение таблиц ===
df_merged2    = df_wh2.merge(xls2, on='Дата', how='left')
df_final_all2 = df_merged2.merge(weather_df2, on='Дата', how='left')

# === 6. Сохранение результата ===
df_final_all2.to_csv("итоговый_датасет2.csv", index=False, encoding='utf-8-sig')

# Просмотр первых 10 строк итогового датасета
print(df_final_all2.head(10))

import pandas as pd

# Предполагается, что у вас уже есть два обработанных DataFrame:
#   df_final_all   — первый датасет с колонками ['Дата','Продажи','Остатки',
#                     'Цена с Ozon Картой','Выручка','Комментариев','Рейтинг', ...]
#   df_final_all2  — второй датасет с колонками ['Дата','Продажи','Остатки', ...]

# 1) Сгруппируем и просуммируем продажи и остатки по датам в каждом из них
agg1 = (
    df_final_all
    .groupby('Дата', as_index=False)
    .agg({'Продажи': 'sum', 'Остатки': 'sum'})
    .rename(columns={'Продажи': 'Продажи_1', 'Остатки': 'Остатки_1'})
)
agg2 = (
    df_final_all2
    .groupby('Дата', as_index=False)
    .agg({'Продажи': 'sum', 'Остатки': 'sum'})
    .rename(columns={'Продажи': 'Продажи_2', 'Остатки': 'Остатки_2'})
)

# 2) Объединим по 'Дата' и сложим
merged = pd.merge(agg1, agg2, on='Дата', how='outer')
merged['Продажи'] = merged['Продажи_1'].fillna(0) + merged['Продажи_2'].fillna(0)
merged['Остатки'] = merged['Остатки_1'].fillna(0) + merged['Остатки_2'].fillna(0)

# 3) Из первого датасета возьмём нужные колонки и уберём дубликаты по дате
first_cols = (
    df_final_all
    [['Дата', 'Цена с Ozon Картой', 'Выручка', 'Комментариев', 'Рейтинг', 'tavg',  'prcp']]
    .drop_duplicates(subset='Дата')
)

# 4) Соберём итоговый DataFrame
final_df = pd.merge(
    first_cols,
    merged[['Дата', 'Продажи', 'Остатки']],
    on='Дата',
    how='right'
)

# 5) Отсортируем по дате и сбросим индекс
final_df = final_df.sort_values('Дата').reset_index(drop=True)

# 6) Посмотрим результат
print(final_df.head())

# 1) Пересчитаем “эталонную” сумму
sum1 = df_final_all.groupby('Дата')['Продажи'].sum()
sum2 = df_final_all2.groupby('Дата')['Продажи'].sum()

# Объединим и сложим, чтобы получить серию эталонных сумм
etalon = (sum1.reindex(final_df['Дата']).fillna(0)
         + sum2.reindex(final_df['Дата']).fillna(0))
etalon.index = final_df['Дата']  # чтобы индексы совпали

# 2) Сравним с тем, что получилось в final_df
diff = final_df.set_index('Дата')['Продажи'] - etalon

# 3) Выведем, есть ли расхождения
if diff.abs().sum() == 0:
    print("Проверка пройдена: все суммы совпадают")
else:
    print("Найдены расхождения по датам:")
    print(diff[diff != 0])

df_combined = final_df.copy()

import matplotlib.pyplot as plt

# Убедимся, что даты отсортированы по возрастанию
df_combined = df_combined.sort_values(by='Дата')

# Строим график
plt.figure(figsize=(12, 6))
plt.plot(df_combined['Дата'], df_combined['Продажи'], label='Продажи', marker='o')
plt.plot(df_combined['Дата'], df_combined['Остатки'], label='Остатки', marker='s')

plt.title('Динамика продаж и остатков')
plt.xlabel('Дата')
plt.ylabel('Количество')
plt.legend()
plt.grid(True)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt

# Убедимся, что даты отсортированы по возрастанию
df_combined = df_combined.sort_values(by='Дата')

# Строим график
plt.figure(figsize=(12, 6))
plt.plot(df_combined['Дата'], df_combined['Продажи'], label='Продажи', marker='o')


plt.title('Динамика продаж')
plt.xlabel('Дата')
plt.ylabel('Количество')
plt.legend()
plt.grid(True)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""СКАЧИВАЕМ ЗАКАЗЫ КОНКУРЕНТОВ

КОНКУРЕНТ1
"""

import pandas as pd

# === 1. Загрузка и парсинг данных продаж ===
file_path_k_1 = "/content/Продажи со складов 262890497 - конкурент 1.csv"
with open(file_path_k_1, 'r', encoding='utf-8') as f_k_1:
    lines_k_1 = f_k_1.readlines()

# Убираем BOM и парсим первую строку с датами в формате дд-мм
raw_dates_k_1 = lines_k_1[0].replace('\ufeff', '').strip().split(';')
dates_k_1 = [d for d in raw_dates_k_1 if '-' in d]

# Автоматическое определение года
parsed_dates_k_1 = []
current_year_k_1 = 2024
last_month_k_1 = 0

for d_k_1 in dates_k_1:
    try:
        day_k_1, month_k_1 = map(int, d_k_1.split('-'))
        if last_month_k_1 == 12 and month_k_1 == 1:
            current_year_k_1 += 1
        dt_k_1 = pd.to_datetime(f"{day_k_1:02d}-{month_k_1:02d}-{current_year_k_1}", format='%d-%m-%Y')
        parsed_dates_k_1.append(dt_k_1)
        last_month_k_1 = month_k_1
    except:
        parsed_dates_k_1.append(None)

date_map_k_1 = pd.Series(parsed_dates_k_1)

# Парсинг строк с данными
parsed_data_k_1 = []
for line_k_1 in lines_k_1[2:]:
    parts_k_1 = line_k_1.strip().split(';')
    warehouse_k_1 = parts_k_1[0]
    values_k_1 = parts_k_1[1:]
    for i_k_1 in range(0, len(values_k_1) - 1, 2):
        idx_k_1 = i_k_1 // 2
        if idx_k_1 < len(date_map_k_1):
            sales_k_1 = values_k_1[i_k_1]
            stock_k_1 = values_k_1[i_k_1 + 1]
            parsed_data_k_1.append((warehouse_k_1, date_map_k_1[idx_k_1], sales_k_1, stock_k_1))

# === 2. DataFrame по выбранным складам ===
df_wh_k_1 = pd.DataFrame(parsed_data_k_1, columns=[
    'Склад_k_1', 'Дата_k_1', 'Продажи_k_1', 'Остатки_k_1'
])

# Задайте список складов, которые нужно оставить
selected_wh_k1 = [
   'ХОРУГВИНО_РФЦ',
    'ГРИВНО_РФЦ',
    'СОФЬИНО_РФЦ',
    'ПУШКИНО_1_РФЦ',
    'ЖУКОВСКИЙ_РФЦ',
    'ПЕТРОВСКОЕ_РФЦ',
    'НОГИНСК_РФЦ',
    'ТВЕРЬ_РФЦ'
]

# Фильтрация сразу по нескольким складам
df_wh_k_1 = df_wh_k_1[df_wh_k_1['Склад_k_1'].isin(selected_wh_k1)]

# Приведение типов
df_wh_k_1['Продажи_k_1'] = pd.to_numeric(df_wh_k_1['Продажи_k_1'], errors='coerce')
df_wh_k_1['Остатки_k_1'] = pd.to_numeric(df_wh_k_1['Остатки_k_1'], errors='coerce')
df_wh_k_1['Дата_k_1']    = pd.to_datetime(df_wh_k_1['Дата_k_1'])

# === 3. Загрузка Excel с доп. столбцами ===
xls_k_1 = pd.read_excel(
    "/content/OZON - 262890497 - Продажи и остатки - 07.08.2024-06.05.2025. (07.05.2025) - конкурент1.xlsx"
)
xls_k_1['Дата_k_1'] = pd.to_datetime(xls_k_1['Дата'], errors='coerce')
xls_k_1.drop(columns='Дата', inplace=True)

xls_k_1 = xls_k_1.rename(columns={
    'Цена с Ozon Картой': 'Цена с Ozon Картой_k_1',
    'Выручка':           'Выручка_k_1',
    'Комментариев':      'Комментариев_k_1',
    'Рейтинг':           'Рейтинг_k_1'
})
xls_k_1 = xls_k_1[[
    'Дата_k_1',
    'Цена с Ozon Картой_k_1',
    'Выручка_k_1',
    'Комментариев_k_1',
    'Рейтинг_k_1'
]]

# === 4. Объединение ===
df_merged_k_1 = (
    df_wh_k_1
    .merge(xls_k_1, on='Дата_k_1', how='left')
    .sort_values(by='Дата_k_1', ascending=True)
    .reset_index(drop=True)
)

# Просмотр результата
print(df_merged_k_1.head())

import pandas as pd

# Убираем колонку склада
df = df_merged_k_1.drop(columns=['Склад_k_1'])

# Группируем по дате и суммируем продажи и остатки
df_grouped = (
    df
    .groupby('Дата_k_1', as_index=False)[['Продажи_k_1', 'Остатки_k_1']]
    .sum()
)

print(df_grouped)

# все строки, где в столбце 'Продажи_k_1' стоит 0
zero_rows = df_grouped[df_grouped['Продажи_k_1'] == 0]
print(zero_rows)

import pandas as pd

# === 1. Загрузка и парсинг данных продаж ===
file_path_k_2 = "/content/Продажи со складов 406951859 конкурент2.csv"
with open(file_path_k_2, 'r', encoding='utf-8') as f_k_2:
    lines_k_2 = f_k_2.readlines()

# Убираем BOM и парсим первую строку с датами в формате дд-мм
raw_dates_k_2 = lines_k_2[0].replace('\ufeff', '').strip().split(';')
dates_k_2 = [d for d in raw_dates_k_2 if '-' in d]

# Автоматическое определение года
parsed_dates_k_2 = []
current_year_k_2 = 2024
last_month_k_2 = 0

for d_k_2 in dates_k_2:
    try:
        day_k_2, month_k_2 = map(int, d_k_2.split('-'))
        if last_month_k_2 == 12 and month_k_2 == 1:
            current_year_k_2 += 1
        dt_k_2 = pd.to_datetime(
            f"{day_k_2:02d}-{month_k_2:02d}-{current_year_k_2}",
            format='%d-%m-%Y'
        )
        parsed_dates_k_2.append(dt_k_2)
        last_month_k_2 = month_k_2
    except:
        parsed_dates_k_2.append(None)

date_map_k_2 = pd.Series(parsed_dates_k_2)

# Парсинг строк с данными
parsed_data_k_2 = []
for line_k_2 in lines_k_2[2:]:
    parts_k_2 = line_k_2.strip().split(';')
    warehouse_k_2 = parts_k_2[0]
    values_k_2 = parts_k_2[1:]
    for i_k_2 in range(0, len(values_k_2) - 1, 2):
        idx_k_2 = i_k_2 // 2
        if idx_k_2 < len(date_map_k_2):
            sales_k_2 = values_k_2[i_k_2]
            stock_k_2 = values_k_2[i_k_2 + 1]
            parsed_data_k_2.append((
                warehouse_k_2,
                date_map_k_2[idx_k_2],
                sales_k_2,
                stock_k_2
            ))

# === 2. DataFrame по выбранным складам ===
df_wh_k_2 = pd.DataFrame(parsed_data_k_2, columns=[
    'Склад_k_2', 'Дата_k_2', 'Продажи_k_2', 'Остатки_k_2'
])

# Задайте список складов, которые нужно оставить
selected_wh_k2 = [
    'ХОРУГВИНО_РФЦ',
    'ГРИВНО_РФЦ',
    'СОФЬИНО_РФЦ',
    'ПУШКИНО_1_РФЦ',
    'ЖУКОВСКИЙ_РФЦ',
    'ПЕТРОВСКОЕ_РФЦ',
    'НОГИНСК_РФЦ',
    'ТВЕРЬ_РФЦ'
]

# Фильтрация сразу по нескольким складам
df_wh_k_2 = df_wh_k_2[df_wh_k_2['Склад_k_2'].isin(selected_wh_k2)]

# Приведение типов
df_wh_k_2['Продажи_k_2'] = pd.to_numeric(df_wh_k_2['Продажи_k_2'], errors='coerce')
df_wh_k_2['Остатки_k_2'] = pd.to_numeric(df_wh_k_2['Остатки_k_2'], errors='coerce')
df_wh_k_2['Дата_k_2']    = pd.to_datetime(df_wh_k_2['Дата_k_2'])

# === 3. Загрузка Excel с доп. столбцами ===
xls_k_2 = pd.read_excel("/content/OZON - 406951859 - конкурент 2.xlsx")
xls_k_2['Дата_k_2'] = pd.to_datetime(xls_k_2['Дата'], errors='coerce')
xls_k_2.drop(columns='Дата', inplace=True)

xls_k_2 = xls_k_2.rename(columns={
    'Цена с Ozon Картой': 'Цена с Ozon Картой_k_2',
    'Выручка':           'Выручка_k_2',
    'Комментариев':      'Комментариев_k_2',
    'Рейтинг':           'Рейтинг_k_2'
})
xls_k_2 = xls_k_2[[
    'Дата_k_2',
    'Цена с Ozon Картой_k_2',
    'Выручка_k_2',
    'Комментариев_k_2',
    'Рейтинг_k_2'
]]

# === 4. Объединение ===
df_merged_k_2 = (
    df_wh_k_2
    .merge(xls_k_2, on='Дата_k_2', how='left')
    .sort_values(by='Дата_k_2', ascending=True)
    .reset_index(drop=True)
)

# Просмотр результата
print(df_merged_k_2.head())

"""Добавление флагов"""

df_merged_k_2

df_combined.shape

df_combined.columns

import pandas as pd
import numpy as np
df = final_df.copy()
# Предположим, что в df есть колонка 'Цена с СПП' и она уже приведена к float
# Шаг 1: посчитаем процентное изменение цены
df['price_pct_change'] = df['Цена с Ozon Картой'].pct_change()

# Шаг 2: введём новый столбец ‘promo’ – флаг акции (1), если цена упала на ≥X%
# Здесь под “значительным” падением возьмём, например, 10%
threshold = -0.10
df['promo'] = (df['price_pct_change'] <= threshold).astype(int)

# (Опционально) Можно посмотреть, сколько таких дней вышло:
print(df['promo'].value_counts())

# Результат:
# promo == 1  → дни, где цена упала на 10% и больше (акция)
# promo == 0  → обычные дни

# Если нужно, можно скорректировать threshold, например:
#   -0.05 для 5%-го падения
#   -0.20 для 20%-го падения

df.head(10)

# 1) Считаем глобальное среднее по колонке 'Цена с СПП'
avg_price = df['Цена с Ozon Картой'].mean()

# 2) Делаем два флага
df['price_above_avg'] = (df['Цена с Ozon Картой'] >  avg_price).astype(int)
df['price_below_avg'] = (df['Цена с Ozon Картой'] <= avg_price).astype(int)

# Проверим
print(f"Средняя цена: {avg_price:.2f}")
print(df[['Цена с Ozon Картой','price_above_avg','price_below_avg']].head(10))

import pandas as pd
import numpy as np

# 1) Считаем процентное изменение цены (если ещё не сделали)
df['price_pct_change'] = df['Цена с Ozon Картой'].pct_change()

# 2) Задаём порог «значительного» увеличения цены, например +10%
threshold_up = 0.10

# 3) Добавляем бинарный флаг price_spike = 1, если цена выросла на threshold_up или больше
df['price_spike'] = (df['price_pct_change'] >= threshold_up).astype(int)

# 4) Смотрим, сколько таких дней
print(df['price_spike'].value_counts())

# скользящее 7-дневное среднее
df['price_roll7'] = df['Цена с Ozon Картой'].rolling(7, min_periods=1).mean()
# флаг, что цена сегодня выше этого 7-дневного локального среднего
df['price_above_roll7'] = (df['Цена с Ozon Картой'] > df['price_roll7']).astype(int)

df.head(-10)

df.columns

df.columns

df['Дата'] = pd.to_datetime(df['Дата'], dayfirst=True)  # Преобразуем строку в дату
df.set_index('Дата', inplace=True)                      # Устанавливаем дату как индекс
df.sort_index(inplace=True)                             # Упорядочим по дате

import numpy as np
import pandas as pd

# 0) Конвертируем и делаем датой индекс
#df['Дата'] = pd.to_datetime(df['Дата'], dayfirst=True)
#df.set_index('Дата', inplace=True)
#df.sort_index(inplace=True)

# --- Теперь можно спокойно создавать все признаки ---

# 1. Календарные признаки
df['dow']         = df.index.dayofweek               # 0=понедельник … 6=воскресенье
df['is_weekend']  = df['dow'].isin([5,6]).astype(int)
df['month']       = df.index.month
df['quarter']     = df.index.quarter
df['day']         = df.index.day
df['day_of_year'] = df.index.dayofyear

# 2. Лаги продаж
for lag in (1, 7, 14, 30):
    df[f'sales_lag_{lag}'] = df['Продажи'].shift(lag)

# 3. Скользящие статистики по продажам
for w in (7, 14, 30):
    df[f'sales_roll_mean_{w}'] = df['Продажи'].rolling(w).mean()
    df[f'sales_roll_std_{w}']  = df['Продажи'].rolling(w).std()

# 4. Признаки по цене
df['price_lag_1']    = df['Цена с Ozon Картой'].shift(1)
df['price_lag_7']    = df['Цена с Ozon Картой'].shift(7)
df['price_pct_1d']   = df['Цена с Ozon Картой'].pct_change(1)
df['price_pct_7d']   = df['Цена с Ozon Картой'].pct_change(7)
df['price_ratio_1d'] = df['Цена с Ozon Картой'].shift(1) / df['Цена с Ozon Картой']

# 5. Погодные признаки
df['prcp_sum_7d']   = df['prcp'].rolling(7).sum()
df['tavg_mean_7d']  = df['tavg'].rolling(7).mean()
df['tavg_anom_30d'] = df['tavg'] - df['tavg'].rolling(30).mean()

# 6. Тренд и Фурье для годовой сезонности
df['time_idx'] = np.arange(len(df))
df['sin_365']  = np.sin(2 * np.pi * df['time_idx'] / 365)
df['cos_365']  = np.cos(2 * np.pi * df['time_idx'] / 365)

# 7. Угловой коэффициент продаж за последние 7 дней
def slope(x):
    if np.isnan(x).any(): return np.nan
    return np.polyfit(np.arange(len(x)), x, 1)[0]
df['sales_slope_7d'] = df['Продажи'].rolling(7).apply(slope, raw=True)

# 8. Помесячная сезонность
# 8.1. Среднее продаж по месяцу
df['month_avg_sales'] = df['Продажи'].groupby(df.index.month).transform('mean')
# 8.2. Dummy-переменные для месяца
month_dummies = pd.get_dummies(df['month'], prefix='month')
df = pd.concat([df, month_dummies], axis=1)

# 9. Удаляем первые строки с NaN, появившиеся из-за shift/rolling
df.fillna(0)

forecast_df = forecast_df.reset_index()        # столбец 'Дата' появляется в DataFrame
forecast_df.drop('index', axis=1, inplace=True)  # если назвался 'index', или
# если reset_index() по-умолчанию назвал столбец 'Дата', то второй строки не надо

df.head()

import pandas as pd
import numpy as np
import statsmodels.api as sm
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

sales      = df['Продажи']
cutoff     = '2025-02-28'
train_sales = sales[:cutoff]
test_sales  = sales['2025-03-01':'2025-03-30']

# --- 1. SARIMAX: экзогенные признаки ---
sarimax_feats = [
    'Цена с Ozon Картой','tavg','prcp',
    'promo','price_spike','price_above_roll7',
    'sales_lag_7','sales_roll_mean_7'
]
exog_df    = df[sarimax_feats].ffill().bfill()
train_exog = exog_df[:cutoff]
test_exog  = exog_df['2025-03-01':'2025-03-30']

def get_sarimax_preds(h):
    model = sm.tsa.SARIMAX(
        train_sales, exog=train_exog,
        order=(1,0,1), seasonal_order=(1,0,1,7)
    ).fit(disp=False)
    return model.forecast(steps=h, exog=test_exog.iloc[:h])

# --- 2. RF/XGB: обучаем на y_{t+1} с готовыми колонками ---
ml_feats = [
    'sales_lag_1','sales_lag_7','sales_roll_mean_7',
    'price_pct_1d','promo','price_spike',
    'dow','is_weekend'
]

df_ml = df.copy()
df_ml['target1'] = sales.shift(-1)
df_ml.dropna(subset=ml_feats + ['target1'], inplace=True)

X_train_ml = df_ml[ml_feats].values
y_train_ml = df_ml['target1'].values

rf  = RandomForestRegressor(n_estimators=200, random_state=0, n_jobs=1).fit(X_train_ml, y_train_ml)
xgb = XGBRegressor(n_estimators=200, random_state=0, seed=0, n_jobs=1, verbosity=0).fit(X_train_ml, y_train_ml)

# --- 3. Рекурсивный прогноз ---
def recursive_preds(h, model):
    preds = []
    history = train_sales.copy()
    for day in test_sales.index[:h]:
        Xday = np.array([[
            history.iloc[-1],
            history.shift(7).iloc[-1],
            history[-7:].mean(),
            df.at[day, 'price_pct_1d'],
            df.at[day, 'promo'],
            df.at[day, 'price_spike'],
            df.at[day, 'dow'],
            df.at[day, 'is_weekend'],
        ]])
        yhat = model.predict(Xday)[0]
        preds.append(yhat)
        history.loc[day] = yhat
    return np.array(preds)

# --- 4. Оценка и визуализация ---
for h in (7, 14, 30):
    dates  = test_sales.index[:h]
    actual = test_sales.iloc[:h].values

    sarimax_p = get_sarimax_preds(h).values
    rf_p      = recursive_preds(h, rf)
    xgb_p     = recursive_preds(h, xgb)

    mae = {
      'SARIMAX': mean_absolute_error(actual, sarimax_p),
      'RF':      mean_absolute_error(actual, rf_p),
      'XGB':     mean_absolute_error(actual, xgb_p)
    }
    rmse = {
      k: np.sqrt(mean_squared_error(actual, eval(f"{k.lower()}_p")))
      for k in mae
    }

    print(f"\nГоризонт {h} дней:")
    for k in mae:
        print(f" {k:<7} MAE={mae[k]:.2f}, RMSE={rmse[k]:.2f}")

    # строим график
    plt.figure(figsize=(8,4))
    plt.plot(dates, actual,    marker='o', label='Факт')
    plt.plot(dates, sarimax_p, linestyle='--', marker='x', label='SARIMAX')
    plt.plot(dates, rf_p,      linestyle='--', marker='x', label='RF')
    plt.plot(dates, xgb_p,     linestyle='--', marker='x', label='XGB')
    plt.title(f'Горизонт {h} дней — факт vs прогноз')
    plt.xticks(rotation=45)
    plt.ylabel('Продажи')
    plt.legend()
    plt.tight_layout()
    plt.show()

# Группируем по горизонту и считаем суммы
summary_df = (
    forecast_df
    .groupby('Горизонт')[['Факт', 'SARIMAX', 'RF', 'XGB']]
    .sum()
    .round(0)
    .rename(columns={
        'Факт': 'Факт, всего',
        'SARIMAX': 'SARIMAX, всего',
        'RF': 'RF, всего',
        'XGB': 'XGB, всего'
    })
    .reset_index()
)

# Показываем финальную таблицу
print("\nСводная таблица прогнозов:")
print(summary_df)

# Сохраняем в файл (по желанию)
summary_df.to_csv("forecast_summary.csv", index=False)

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error
import pandas as pd
import numpy as np

def single_feature_importance(df, features, target_col='Продажи', cutoff='2025-02-28'):
    """
    Оценивает вклад каждого признака отдельно в прогноз продаж.
    """
    results = []

    df = df.copy()
    df.index = pd.to_datetime(df['Дата']) if 'Дата' in df.columns else df.index
    df = df.sort_index()

    train_df = df[df.index <= cutoff].copy()
    test_df  = df[(df.index > cutoff) & (df.index <= '2025-03-30')].copy()

    for feat in features:
        try:
            train = train_df[[feat, target_col]].dropna()
            test  = test_df[[feat, target_col]].dropna()

            X_train = train[[feat]].values
            y_train = train[target_col].values
            X_test  = test[[feat]].values
            y_test  = test[target_col].values

            model = RandomForestRegressor(n_estimators=100, random_state=42)
            model.fit(X_train, y_train)
            preds = model.predict(X_test)

            mae  = mean_absolute_error(y_test, preds)
            rmse = np.sqrt(mean_squared_error(y_test, preds))

            results.append((feat, mae, rmse))
        except Exception as e:
            print(f"Ошибка в признаке {feat}: {e}")
            continue

    return pd.DataFrame(results, columns=['Feature', 'MAE', 'RMSE']).sort_values(by='MAE').reset_index(drop=True)

feature_list = [
    'Остатки', 'Цена с Ozon Картой', 'Выручка',
       'Комментариев', 'Рейтинг', 'tavg', 'prcp', 'Цена с Ozon Картой2', 'k_1',
       'k_2', 'price_pct_change', 'promo', 'price_above_avg',
       'price_below_avg', 'price_spike', 'price_roll7', 'price_above_roll7',
       'dow', 'is_weekend', 'month', 'quarter', 'day', 'day_of_year',
       'sales_lag_1', 'sales_lag_7', 'sales_lag_14', 'sales_lag_30',
       'sales_roll_mean_7', 'sales_roll_std_7', 'sales_roll_mean_14',
       'sales_roll_std_14', 'sales_roll_mean_30', 'sales_roll_std_30',
       'price_lag_1', 'price_lag_7', 'price_pct_1d', 'price_pct_7d',
       'price_ratio_1d', 'prcp_sum_7d', 'tavg_mean_7d', 'tavg_anom_30d',
       'time_idx', 'sin_365', 'cos_365', 'sales_slope_7d', 'month_avg_sales',
       'month_1', 'month_2', 'month_3', 'month_4', 'month_5', 'month_8',
       'month_9', 'month_10', 'month_11', 'month_12'
]

result_single = single_feature_importance(df, feature_list)
print(result_single)

df.head(10)

import matplotlib.pyplot as plt
import numpy as np

# 1. Отбираем только числовые столбцы
numeric_df = df.select_dtypes(include=[np.number])

# 2. Считаем корреляцию
corr = numeric_df.corr()

# 3. Строим тепловую карту
fig, ax = plt.subplots(figsize=(12, 10))
cax = ax.imshow(corr.values, aspect='auto', cmap='viridis')
ax.set_xticks(np.arange(len(corr.columns)))
ax.set_yticks(np.arange(len(corr.columns)))
ax.set_xticklabels(corr.columns, rotation=90)
ax.set_yticklabels(corr.columns)
fig.colorbar(cax, label='Корреляция')
plt.title('Тепловая карта корреляции числовых признаков')
plt.tight_layout()
plt.show()

Index(['Цена с Ozon Картой', 'Выручка', 'Комментариев', 'Рейтинг', 'tavg',
       'prcp', 'Продажи', 'Остатки', 'price_pct_change', 'promo',
       'price_above_avg', 'price_below_avg', 'price_spike', 'price_roll7',
       'price_above_roll7', 'dow', 'is_weekend', 'month', 'quarter', 'day',
       'day_of_year', 'sales_lag_1', 'sales_lag_7', 'sales_lag_14',
       'sales_lag_30', 'sales_roll_mean_7', 'sales_roll_std_7',
       'sales_roll_mean_14', 'sales_roll_std_14', 'sales_roll_mean_14',
       'sales_roll_std_30', 'price_lag_1', 'price_lag_7', 'price_pct_1d',
       'price_pct_7d', 'price_ratio_1d', 'prcp_sum_7d', 'tavg_mean_7d',
       'tavg_anom_30d', 'time_idx', 'sin_365', 'cos_365', 'sales_slope_7d',
       'month_avg_sales', 'month_1', 'month_2', 'month_3', 'month_4',
       'month_5', 'month_8', 'month_9', 'month_10', 'month_11', 'month_12'],
      dtype='object')
 'sales_lag_1','sales_roll_mean_7','sales_roll_mean_14','month_avg_sales','sales_slope_7d','sales_roll_mean_14','sales_roll_mean_14','Комментариев'

'Остатки','price_above_avg','price_roll7', 'month', 'quarter', 'day_of_year','sin_365','Цена с Ozon Картой'

df.columns

import pandas as pd
import numpy as np
import statsmodels.api as sm
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
import matplotlib.pyplot as plt
from sklearn.metrics import mean_absolute_error, mean_squared_error
import warnings
warnings.filterwarnings('ignore')

# 0. Подготовка индекса и целевой
if 'Дата' in df.columns:
    df.index = pd.to_datetime(df['Дата'])
sales = df['Продажи']

# 1. Параметры
cutoff         = '2025-02-28'
forecast_start = '2025-03-01'
forecast_end   = '2025-03-30'
forecast_dates = pd.date_range(forecast_start, forecast_end, freq='D')

# 2. Наборы признаков (можно менять)
exog_feats = [
    'Остатки','price_above_avg','price_roll7',
    'month','quarter','day_of_year','sin_365',
    'Цена с Ozon Картой'
]
ml_feats = exog_feats.copy()  # можно задать свой список

# 3. Готовим экзогены для SARIMAX
exog_df    = df[exog_feats].ffill().bfill().astype(float)
train_exog = exog_df.loc[:cutoff]
test_exog  = exog_df.reindex(forecast_dates)

def forecast_sarimax(train_sales, train_exog, test_exog):
    model = sm.tsa.SARIMAX(
        train_sales, exog=train_exog,
        order=(1,0,1), seasonal_order=(1,0,1,7),
        enforce_stationarity=False, enforce_invertibility=False
    ).fit(disp=False)
    return model.forecast(steps=len(test_exog), exog=test_exog)

# 4. SARIMAX-прогноз
train_sales   = sales.loc[:cutoff]
sarimax_preds = forecast_sarimax(train_sales, train_exog, test_exog)

# 5. Обучаем RF и XGB на одношаговом прогнозе
df_ml = df.copy()
df_ml['target'] = sales.shift(-1)
df_ml.dropna(subset=ml_feats + ['target'], inplace=True)

X_train = df_ml[ml_feats].values
y_train = df_ml['target'].values

rf  = RandomForestRegressor(n_estimators=200, random_state=0).fit(X_train, y_train)
xgb = XGBRegressor(n_estimators=200, random_state=0, verbosity=0).fit(X_train, y_train)

# 6. Рекурсивный прогноз для ML
def recursive_forecast(df, train_sales, model, ml_feats, dates):
    preds = []
    history = train_sales.copy()
    for day in dates:
        feat_row = []
        for f in ml_feats:
            if f.startswith('sales_'):
                if 'lag_' in f:
                    lag = int(f.split('_')[-1]); feat_row.append(history.shift(lag).iloc[-1])
                elif 'roll_mean_' in f:
                    w = int(f.split('_')[-1]); feat_row.append(history[-w:].mean())
                elif 'roll_std_' in f:
                    w = int(f.split('_')[-1]); feat_row.append(history[-w:].std())
                else:
                    feat_row.append(history.iloc[-1])
            else:
                feat_row.append(df.at[day, f])
        preds_day = model.predict(np.array([feat_row]))[0]
        preds.append(preds_day)
        history.loc[day] = preds_day
    return np.array(preds)

rf_preds  = recursive_forecast(df, train_sales, rf,  ml_feats, forecast_dates)
xgb_preds = recursive_forecast(df, train_sales, xgb, ml_feats, forecast_dates)

# 7. Сводный DataFrame прогнозов
forecast_df = pd.DataFrame({
    'Факт':    sales.reindex(forecast_dates),
    'SARIMAX': np.round(sarimax_preds).astype(int),
    'RF':      np.round(rf_preds).astype(int),
    'XGB':     np.round(xgb_preds).astype(int),
}, index=forecast_dates)

horizons = [7, 14, 30]

for h in horizons:
    dates_h = forecast_dates[:h]
    plt.figure(figsize=(10, 4))
    # Факт
    plt.plot(
        dates_h,
        forecast_df.loc[dates_h, 'Факт'],
        marker='o',
        label='Факт'
    )
    # SARIMAX
    plt.plot(
        dates_h,
        forecast_df.loc[dates_h, 'SARIMAX'],
        linestyle='--',
        marker='x',
        label='SARIMAX'
    )
    # RF
    plt.plot(
        dates_h,
        forecast_df.loc[dates_h, 'RF'],
        linestyle='--',
        marker='x',
        label='RF'
    )
    # XGB
    plt.plot(
        dates_h,
        forecast_df.loc[dates_h, 'XGB'],
        linestyle='--',
        marker='x',
        label='XGB'
    )

    plt.title(f'Факт vs прогнозы (горизонт {h} дней)')
    plt.xlabel('Дата')
    plt.ylabel('Продажи')
    plt.xticks(rotation=45)
    plt.legend()
    plt.tight_layout()
    plt.show()

# 9. Таблица сумм по горизонтам и моделям
horizons = [7, 14, 30]
rows = []
for h in horizons:
    dates_h   = forecast_dates[:h]
    actual_sum = forecast_df.loc[dates_h, 'Факт'].sum()
    row = {'Горизонт (дн)': h, 'Факт (сумма)': int(actual_sum)}
    for m in ['SARIMAX','RF','XGB']:
        pred_sum = forecast_df.loc[dates_h, m].sum()
        row[f'{m} (сумма)'] = int(pred_sum)
        row[f'{m} MAE']     = mean_absolute_error(forecast_df.loc[dates_h, 'Факт'], forecast_df.loc[dates_h, m])
        row[f'{m} RMSE']    = np.sqrt(mean_squared_error(forecast_df.loc[dates_h, 'Факт'], forecast_df.loc[dates_h, m]))
    rows.append(row)

summary_df = pd.DataFrame(rows)
print("\nСводная таблица по горизонтам:")
print(summary_df.to_string(index=False))

import pandas as pd
import numpy as np
import statsmodels.api as sm
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
import matplotlib.pyplot as plt
from sklearn.metrics import mean_absolute_error, mean_squared_error
import warnings
warnings.filterwarnings('ignore')

# 0. Подготовка индекса и целевого
if 'Дата' in df.columns:
    df.index = pd.to_datetime(df['Дата'])
sales = df['Продажи']

# 1. Параметры
cutoff         = '2025-02-28'
forecast_start = '2025-03-01'
forecast_end   = '2025-03-30'
forecast_dates = pd.date_range(forecast_start, forecast_end, freq='D')

# 2. Отдельные списки признаков
sarimax_feats = [
    'sales_lag_1','sales_lag_7','sales_lag_30',
    'price_above_avg','price_below_avg','sales_slope_7d',
    'day_of_year','promo'
]

ml_feats = [
    'Остатки','price_above_avg','price_roll7',
    'month','quarter','day_of_year','sin_365',
    'Цена с Ozon Картой'
]

# 3. Готовим экзогены для SARIMAX
exog_df    = df[sarimax_feats].ffill().bfill().astype(float)
train_exog = exog_df.loc[:cutoff]
test_exog  = exog_df.reindex(forecast_dates)

def forecast_sarimax(train_sales, train_exog, test_exog):
    model = sm.tsa.SARIMAX(
        train_sales, exog=train_exog,
        order=(1,0,1), seasonal_order=(1,0,1,7),
        enforce_stationarity=False, enforce_invertibility=False
    ).fit(disp=False)
    return model.forecast(steps=len(test_exog), exog=test_exog)

# 4. SARIMAX-прогноз
train_sales   = sales.loc[:cutoff]
sarimax_preds = forecast_sarimax(train_sales, train_exog, test_exog)

# 5. Подготовка данных для ML
df_ml = df.copy()
df_ml['target'] = sales.shift(-1)
df_ml.dropna(subset=ml_feats + ['target'], inplace=True)

X_train = df_ml[ml_feats].values
y_train = df_ml['target'].values

rf  = RandomForestRegressor(n_estimators=200, random_state=0).fit(X_train, y_train)
xgb = XGBRegressor(n_estimators=200, random_state=0, verbosity=0).fit(X_train, y_train)

# 6. Рекурсивный прогноз для ML
def recursive_forecast(df, train_sales, model, ml_feats, dates):
    preds = []
    history = train_sales.copy()
    for day in dates:
        feat_row = []
        for f in ml_feats:
            if f.startswith('sales_'):
                lag = int(f.split('_')[-1])
                feat_row.append(history.shift(lag).iloc[-1])
            else:
                feat_row.append(df.at[day, f])
        preds_day = model.predict(np.array([feat_row]))[0]
        preds.append(preds_day)
        history.loc[day] = preds_day
    return np.array(preds)

rf_preds  = recursive_forecast(df, train_sales, rf,  ml_feats, forecast_dates)
xgb_preds = recursive_forecast(df, train_sales, xgb, ml_feats, forecast_dates)

# 7. Сводный DataFrame прогнозов
forecast_df = pd.DataFrame({
    'Факт':    sales.reindex(forecast_dates),
    'SARIMAX': np.round(sarimax_preds).astype(int),
    'RF':      np.round(rf_preds).astype(int),
    'XGB':     np.round(xgb_preds).astype(int),
}, index=forecast_dates)
horizons = [7, 14, 30]

for h in horizons:
    dates_h = forecast_dates[:h]
    plt.figure(figsize=(10, 4))
    # Факт
    plt.plot(
        dates_h,
        forecast_df.loc[dates_h, 'Факт'],
        marker='o',
        label='Факт'
    )
    # SARIMAX
    plt.plot(
        dates_h,
        forecast_df.loc[dates_h, 'SARIMAX'],
        linestyle='--',
        marker='x',
        label='SARIMAX'
    )
    # RF
    plt.plot(
        dates_h,
        forecast_df.loc[dates_h, 'RF'],
        linestyle='--',
        marker='x',
        label='RF'
    )
    # XGB
    plt.plot(
        dates_h,
        forecast_df.loc[dates_h, 'XGB'],
        linestyle='--',
        marker='x',
        label='XGB'
    )

    plt.title(f'Факт vs прогнозы (горизонт {h} дней)')
    plt.xlabel('Дата')
    plt.ylabel('Продажи')
    plt.xticks(rotation=45)
    plt.legend()
    plt.tight_layout()
    plt.show()

# 9. Таблица сумм по горизонтам и моделям
horizons = [7, 14, 30]
rows = []
for h in horizons:
    dates_h   = forecast_dates[:h]
    actual_sum = forecast_df.loc[dates_h, 'Факт'].sum()
    row = {'Горизонт (дн)': h, 'Факт (сумма)': int(actual_sum)}
    for m in ['SARIMAX','RF','XGB']:
        pred_sum = forecast_df.loc[dates_h, m].sum()
        row[f'{m} (сумма)'] = int(pred_sum)
        row[f'{m} MAE']     = mean_absolute_error(forecast_df.loc[dates_h, 'Факт'], forecast_df.loc[dates_h, m])
        row[f'{m} RMSE']    = np.sqrt(mean_squared_error(forecast_df.loc[dates_h, 'Факт'], forecast_df.loc[dates_h, m]))
    rows.append(row)

summary_df = pd.DataFrame(rows)
print("\nСводная таблица по горизонтам:")
print(summary_df.to_string(index=False))